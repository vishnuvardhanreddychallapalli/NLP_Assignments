{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3: Language Modeling Fundamentals\n",
    "\n",
    "Lecture 3 | CMU ANLP Spring 2025 | Instructor: Sean Welleck\n",
    "\n",
    "#### Part 2: Feedforward neural language model\n",
    "\n",
    "This is a notebook for [CMU CS11-711 Advanced NLP](https://cmu-l3.github.io/anlp-spring2025/) that trains a feedforward language model, i.e. one based on [Bengio et al 2003, A Neural Probabilistic Language Model](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = open('names.txt').read().splitlines()\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_index = {tok: i for i, tok in enumerate('abcdefghijklmnopqrstuvwxyz')}\n",
    "token_to_index['[S]'] = 26\n",
    "index_to_token = {i: tok for tok, i in token_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the dataset\n",
    "\n",
    "Our dataset consists of $x,y$ pairs, where $x$ is a $(n-1)$-token context, and $y$ is a token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([182427, 5]), torch.Size([182427]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "context_size = 5\n",
    "\n",
    "def build_dataset(data):\n",
    "    X, Y = [], []\n",
    "    for item in data:\n",
    "        context = [token_to_index['[S]']] * context_size\n",
    "        tokens = list(item) + ['[S]']\n",
    "        for token in tokens:\n",
    "            X.append(context)\n",
    "            Y.append(token_to_index[token])\n",
    "            context = context[1:] + [token_to_index[token]]\n",
    "            #print(\"XVAL............\",X)\n",
    "            #print(\"YVAL............\",Y)\n",
    "            #print(\"Context.........\",context)\n",
    "            #break\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    return X, Y\n",
    "\n",
    "# Split into train, dev, test\n",
    "import random\n",
    "random.seed(123)\n",
    "random.shuffle(data)\n",
    "\n",
    "n1 = int(0.8 * len(data))\n",
    "n2 = int(0.9 * len(data))\n",
    "\n",
    "X_train, Y_train = build_dataset(data[:n1])\n",
    "X_dev, Y_dev = build_dataset(data[n1:n2])\n",
    "X_test, Y_test = build_dataset(data[n2:])\n",
    "\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE ITEM IS............ luann\n",
      "BEFORE ........... [26, 26, 26, 26, 26]     ['l', 'u', 'a', 'n', 'n', '[S]']\n",
      "THE TOKEN IS...... l\n",
      "[26, 26, 26, 26, 26]\n",
      "11\n",
      "******************************\n",
      "THE TOKEN IS...... u\n",
      "[26, 26, 26, 26, 11]\n",
      "20\n",
      "******************************\n",
      "THE TOKEN IS...... a\n",
      "[26, 26, 26, 11, 20]\n",
      "0\n",
      "******************************\n",
      "THE TOKEN IS...... n\n",
      "[26, 26, 11, 20, 0]\n",
      "13\n",
      "******************************\n",
      "THE TOKEN IS...... n\n",
      "[26, 11, 20, 0, 13]\n",
      "13\n",
      "******************************\n",
      "THE TOKEN IS...... [S]\n",
      "[11, 20, 0, 13, 13]\n",
      "26\n",
      "******************************\n",
      "THE ITEM IS............ shain\n",
      "BEFORE ........... [26, 26, 26, 26, 26]     ['s', 'h', 'a', 'i', 'n', '[S]']\n",
      "THE TOKEN IS...... s\n",
      "[26, 26, 26, 26, 26]\n",
      "18\n",
      "******************************\n",
      "THE TOKEN IS...... h\n",
      "[26, 26, 26, 26, 18]\n",
      "7\n",
      "******************************\n",
      "THE TOKEN IS...... a\n",
      "[26, 26, 26, 18, 7]\n",
      "0\n",
      "******************************\n",
      "THE TOKEN IS...... i\n",
      "[26, 26, 18, 7, 0]\n",
      "8\n",
      "******************************\n",
      "THE TOKEN IS...... n\n",
      "[26, 18, 7, 0, 8]\n",
      "13\n",
      "******************************\n",
      "THE TOKEN IS...... [S]\n",
      "[18, 7, 0, 8, 13]\n",
      "26\n",
      "******************************\n",
      "THE ITEM IS............ rupert\n",
      "BEFORE ........... [26, 26, 26, 26, 26]     ['r', 'u', 'p', 'e', 'r', 't', '[S]']\n",
      "THE TOKEN IS...... r\n",
      "[26, 26, 26, 26, 26]\n",
      "17\n",
      "******************************\n",
      "THE TOKEN IS...... u\n",
      "[26, 26, 26, 26, 17]\n",
      "20\n",
      "******************************\n",
      "THE TOKEN IS...... p\n",
      "[26, 26, 26, 17, 20]\n",
      "15\n",
      "******************************\n",
      "THE TOKEN IS...... e\n",
      "[26, 26, 17, 20, 15]\n",
      "4\n",
      "******************************\n",
      "THE TOKEN IS...... r\n",
      "[26, 17, 20, 15, 4]\n",
      "17\n",
      "******************************\n",
      "THE TOKEN IS...... t\n",
      "[17, 20, 15, 4, 17]\n",
      "19\n",
      "******************************\n",
      "THE TOKEN IS...... [S]\n",
      "[20, 15, 4, 17, 19]\n",
      "26\n",
      "******************************\n",
      "THE ITEM IS............ mokshagna\n",
      "BEFORE ........... [26, 26, 26, 26, 26]     ['m', 'o', 'k', 's', 'h', 'a', 'g', 'n', 'a', '[S]']\n",
      "THE TOKEN IS...... m\n",
      "[26, 26, 26, 26, 26]\n",
      "12\n",
      "******************************\n",
      "THE TOKEN IS...... o\n",
      "[26, 26, 26, 26, 12]\n",
      "14\n",
      "******************************\n",
      "THE TOKEN IS...... k\n",
      "[26, 26, 26, 12, 14]\n",
      "10\n",
      "******************************\n",
      "THE TOKEN IS...... s\n",
      "[26, 26, 12, 14, 10]\n",
      "18\n",
      "******************************\n",
      "THE TOKEN IS...... h\n",
      "[26, 12, 14, 10, 18]\n",
      "7\n",
      "******************************\n",
      "THE TOKEN IS...... a\n",
      "[12, 14, 10, 18, 7]\n",
      "0\n",
      "******************************\n",
      "THE TOKEN IS...... g\n",
      "[14, 10, 18, 7, 0]\n",
      "6\n",
      "******************************\n",
      "THE TOKEN IS...... n\n",
      "[10, 18, 7, 0, 6]\n",
      "13\n",
      "******************************\n",
      "THE TOKEN IS...... a\n",
      "[18, 7, 0, 6, 13]\n",
      "0\n",
      "******************************\n",
      "THE TOKEN IS...... [S]\n",
      "[7, 0, 6, 13, 0]\n",
      "26\n",
      "******************************\n",
      "THE ITEM IS............ enric\n",
      "BEFORE ........... [26, 26, 26, 26, 26]     ['e', 'n', 'r', 'i', 'c', '[S]']\n",
      "THE TOKEN IS...... e\n",
      "[26, 26, 26, 26, 26]\n",
      "4\n",
      "******************************\n",
      "THE TOKEN IS...... n\n",
      "[26, 26, 26, 26, 4]\n",
      "13\n",
      "******************************\n",
      "THE TOKEN IS...... r\n",
      "[26, 26, 26, 4, 13]\n",
      "17\n",
      "******************************\n",
      "THE TOKEN IS...... i\n",
      "[26, 26, 4, 13, 17]\n",
      "8\n",
      "******************************\n",
      "THE TOKEN IS...... c\n",
      "[26, 4, 13, 17, 8]\n",
      "2\n",
      "******************************\n",
      "THE TOKEN IS...... [S]\n",
      "[4, 13, 17, 8, 2]\n",
      "26\n",
      "******************************\n",
      "THE ITEM IS............ lynnette\n",
      "BEFORE ........... [26, 26, 26, 26, 26]     ['l', 'y', 'n', 'n', 'e', 't', 't', 'e', '[S]']\n",
      "THE TOKEN IS...... l\n",
      "[26, 26, 26, 26, 26]\n",
      "11\n",
      "******************************\n",
      "THE TOKEN IS...... y\n",
      "[26, 26, 26, 26, 11]\n",
      "24\n",
      "******************************\n",
      "THE TOKEN IS...... n\n",
      "[26, 26, 26, 11, 24]\n",
      "13\n",
      "******************************\n",
      "THE TOKEN IS...... n\n",
      "[26, 26, 11, 24, 13]\n",
      "13\n",
      "******************************\n",
      "THE TOKEN IS...... e\n",
      "[26, 11, 24, 13, 13]\n",
      "4\n",
      "******************************\n",
      "THE TOKEN IS...... t\n",
      "[11, 24, 13, 13, 4]\n",
      "19\n",
      "******************************\n",
      "THE TOKEN IS...... t\n",
      "[24, 13, 13, 4, 19]\n",
      "19\n",
      "******************************\n",
      "THE TOKEN IS...... e\n",
      "[13, 13, 4, 19, 19]\n",
      "4\n",
      "******************************\n",
      "THE TOKEN IS...... [S]\n",
      "[13, 4, 19, 19, 4]\n",
      "26\n",
      "******************************\n",
      "THE ITEM IS............ layali\n",
      "BEFORE ........... [26, 26, 26, 26, 26]     ['l', 'a', 'y', 'a', 'l', 'i', '[S]']\n",
      "THE TOKEN IS...... l\n",
      "[26, 26, 26, 26, 26]\n",
      "11\n",
      "******************************\n",
      "THE TOKEN IS...... a\n",
      "[26, 26, 26, 26, 11]\n",
      "0\n",
      "******************************\n",
      "THE TOKEN IS...... y\n",
      "[26, 26, 26, 11, 0]\n",
      "24\n",
      "******************************\n",
      "THE TOKEN IS...... a\n",
      "[26, 26, 11, 0, 24]\n",
      "0\n",
      "******************************\n",
      "THE TOKEN IS...... l\n",
      "[26, 11, 0, 24, 0]\n",
      "11\n",
      "******************************\n",
      "THE TOKEN IS...... i\n",
      "[11, 0, 24, 0, 11]\n",
      "8\n",
      "******************************\n",
      "THE TOKEN IS...... [S]\n",
      "[0, 24, 0, 11, 8]\n",
      "26\n",
      "******************************\n",
      "THE ITEM IS............ johnryan\n",
      "BEFORE ........... [26, 26, 26, 26, 26]     ['j', 'o', 'h', 'n', 'r', 'y', 'a', 'n', '[S]']\n",
      "THE TOKEN IS...... j\n",
      "[26, 26, 26, 26, 26]\n",
      "9\n",
      "******************************\n",
      "THE TOKEN IS...... o\n",
      "[26, 26, 26, 26, 9]\n",
      "14\n",
      "******************************\n",
      "THE TOKEN IS...... h\n",
      "[26, 26, 26, 9, 14]\n",
      "7\n",
      "******************************\n",
      "THE TOKEN IS...... n\n",
      "[26, 26, 9, 14, 7]\n",
      "13\n",
      "******************************\n",
      "THE TOKEN IS...... r\n",
      "[26, 9, 14, 7, 13]\n",
      "17\n",
      "******************************\n",
      "THE TOKEN IS...... y\n",
      "[9, 14, 7, 13, 17]\n",
      "24\n",
      "******************************\n",
      "THE TOKEN IS...... a\n",
      "[14, 7, 13, 17, 24]\n",
      "0\n",
      "******************************\n",
      "THE TOKEN IS...... n\n",
      "[7, 13, 17, 24, 0]\n",
      "13\n",
      "******************************\n",
      "THE TOKEN IS...... [S]\n",
      "[13, 17, 24, 0, 13]\n",
      "26\n",
      "******************************\n",
      "THE ITEM IS............ scarlet\n",
      "BEFORE ........... [26, 26, 26, 26, 26]     ['s', 'c', 'a', 'r', 'l', 'e', 't', '[S]']\n",
      "THE TOKEN IS...... s\n",
      "[26, 26, 26, 26, 26]\n",
      "18\n",
      "******************************\n",
      "THE TOKEN IS...... c\n",
      "[26, 26, 26, 26, 18]\n",
      "2\n",
      "******************************\n",
      "THE TOKEN IS...... a\n",
      "[26, 26, 26, 18, 2]\n",
      "0\n",
      "******************************\n",
      "THE TOKEN IS...... r\n",
      "[26, 26, 18, 2, 0]\n",
      "17\n",
      "******************************\n",
      "THE TOKEN IS...... l\n",
      "[26, 18, 2, 0, 17]\n",
      "11\n",
      "******************************\n",
      "THE TOKEN IS...... e\n",
      "[18, 2, 0, 17, 11]\n",
      "4\n",
      "******************************\n",
      "THE TOKEN IS...... t\n",
      "[2, 0, 17, 11, 4]\n",
      "19\n",
      "******************************\n",
      "THE TOKEN IS...... [S]\n",
      "[0, 17, 11, 4, 19]\n",
      "26\n",
      "******************************\n",
      "THE ITEM IS............ yasseen\n",
      "BEFORE ........... [26, 26, 26, 26, 26]     ['y', 'a', 's', 's', 'e', 'e', 'n', '[S]']\n"
     ]
    }
   ],
   "source": [
    "context_size = 5\n",
    "\n",
    "\n",
    "maxiter=0\n",
    "\n",
    "X, Y = [], []\n",
    "for item in data:\n",
    "    print(\"THE ITEM IS............\",item)\n",
    "    context = [token_to_index['[S]']] * context_size\n",
    "    tokens = list(item) + ['[S]']\n",
    "    print(\"BEFORE ...........\",context,\"   \",tokens)\n",
    "    maxiter=maxiter+1\n",
    "    if maxiter==10:\n",
    "        break\n",
    "    for token in tokens:\n",
    "        print(\"THE TOKEN IS......\",token)\n",
    "        print(context)\n",
    "        print(token_to_index[token])\n",
    "        context = context[1:] + [token_to_index[token]]\n",
    "        print(\"******************************\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLPLM(nn.Module):\n",
    "    def __init__(self, vocab_size, context_size, embedding_size, hidden_size):\n",
    "        super(MLPLM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.fc1 = nn.Linear(context_size * embedding_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)       # (batch_size, context_size, hidden_size)\n",
    "        x = x.view(x.shape[0], -1)  # (batch_size, context_size * hidden_size)\n",
    "        x = torch.relu(self.fc1(x)) # (batch_size, hidden_size)\n",
    "        x = self.fc2(x)             # (batch_size, vocab_size)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[26, 26, 26, 26, 26],\n",
       "        [26, 26, 26, 26, 11]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLPLM(len(token_to_index), context_size, 64, 64)\n",
    "\n",
    "x = X_train[:2]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2176,  0.0954,  0.2361, -0.1520, -0.4687,  0.0696,  0.2823,  0.1976,\n",
       "         -0.0093, -0.3868,  0.0382,  0.0110, -0.0343,  0.0773,  0.0686,  0.1706,\n",
       "          0.0908, -0.1641,  0.0681,  0.0134,  0.1676, -0.0883, -0.3497, -0.0940,\n",
       "         -0.0150,  0.0009,  0.1949],\n",
       "        [ 0.2027,  0.0857,  0.0941, -0.0693, -0.3242, -0.1245,  0.1153,  0.0473,\n",
       "         -0.0010, -0.3164, -0.0733,  0.1544, -0.0319,  0.0842,  0.0415,  0.2588,\n",
       "          0.0507, -0.2100, -0.0416, -0.0168,  0.1277,  0.1366, -0.2911, -0.0395,\n",
       "          0.0083,  0.0684,  0.1101]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 24027\n",
      "Epoch [1/10], Loss: 2.2235\n",
      "Epoch [2/10], Loss: 2.1249\n",
      "Epoch [3/10], Loss: 2.0985\n",
      "Epoch [4/10], Loss: 2.0841\n",
      "Epoch [5/10], Loss: 2.0747\n",
      "Epoch [6/10], Loss: 2.0674\n",
      "Epoch [7/10], Loss: 2.0616\n",
      "Epoch [8/10], Loss: 2.0570\n",
      "Epoch [9/10], Loss: 2.0534\n",
      "Epoch [10/10], Loss: 2.0509\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = MLPLM(len(token_to_index), context_size, 64, 64)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "# Loss function and optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Reshuffle the data\n",
    "    perm = torch.randperm(len(X_train))\n",
    "    X_train = X_train[perm]\n",
    "    Y_train = Y_train[perm]\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        X_batch = X_train[i:i+batch_size]\n",
    "        Y_batch = Y_train[i:i+batch_size]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, Y_batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / (len(X_train) // batch_size)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from the model\n",
    "def sample(model, context, max_length=100):\n",
    "    model.eval()\n",
    "    output = []\n",
    "    with torch.no_grad():\n",
    "        context = torch.tensor(context).unsqueeze(0)\n",
    "        for i in range(max_length):\n",
    "            logits = model(context)\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            token = torch.multinomial(probs, num_samples=1)\n",
    "            context = torch.cat([context[:, 1:], token], dim=1)\n",
    "\n",
    "            output.append(index_to_token[token.item()])\n",
    "            if index_to_token[token.item()] == '[S]':\n",
    "                return ''.join(output)\n",
    "    return ''.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eliphan[S]\n",
      "ceevy[S]\n",
      "buint[S]\n",
      "nuhiba[S]\n",
      "hilil[S]\n",
      "nelay[S]\n",
      "aadir[S]\n",
      "braylan[S]\n",
      "caarleya[S]\n",
      "myla[S]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(sample(model, [token_to_index['[S]']] * context_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT HERE........... [26, 26, 26, 26, 18]\n",
      "sidden[S]\n",
      "INPUT HERE........... [26, 26, 26, 26, 18]\n",
      "shav[S]\n",
      "INPUT HERE........... [26, 26, 26, 26, 18]\n",
      "sandre[S]\n",
      "INPUT HERE........... [26, 26, 26, 26, 18]\n",
      "stontin[S]\n",
      "INPUT HERE........... [26, 26, 26, 26, 18]\n",
      "solerh[S]\n",
      "INPUT HERE........... [26, 26, 26, 26, 18]\n",
      "sybitolani[S]\n",
      "INPUT HERE........... [26, 26, 26, 26, 18]\n",
      "sjaicobe[S]\n",
      "INPUT HERE........... [26, 26, 26, 26, 18]\n",
      "siger[S]\n",
      "INPUT HERE........... [26, 26, 26, 26, 18]\n",
      "shayla[S]\n",
      "INPUT HERE........... [26, 26, 26, 26, 18]\n",
      "syren[S]\n"
     ]
    }
   ],
   "source": [
    "prompt = 's'\n",
    "for i in range(10):\n",
    "    print(\"INPUT HERE...........\",([token_to_index['[S]']] * (context_size-len(prompt))) + [token_to_index[c] for c in prompt])\n",
    "    out = sample(model, ([token_to_index['[S]']] * (context_size-len(prompt))) + [token_to_index[c] for c in prompt])\n",
    "    print(prompt + out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
